# ðŸ§  Smart Labeling System - DocumentaciÃ³n

Sistema inteligente de etiquetado y entrenamiento de modelos de predicciÃ³n de explotabilidad para vulnerabilidades 5G.

---

## ðŸ“‹ Tabla de Contenidos

1. [IntroducciÃ³n](#introducciÃ³n)
2. [InstalaciÃ³n](#instalaciÃ³n)
3. [Arquitectura](#arquitectura)
4. [Uso RÃ¡pido](#uso-rÃ¡pido)
5. [Scripts Disponibles](#scripts-disponibles)
6. [Workflow Completo](#workflow-completo)
7. [InterpretaciÃ³n de Resultados](#interpretaciÃ³n-de-resultados)
8. [FAQ](#faq)

---

## ðŸŽ¯ IntroducciÃ³n

### Problema Original

El sistema de etiquetado heurÃ­stico simple tenÃ­a varios problemas:

- **Sesgo hacia DoS**: 29% de CVEs eran DoS, tratados igual que RCE
- **Sin clasificar**: 15% de CVEs sin tipo, ignorados por el modelo
- **Falsos positivos**: DoS con CVSS 7.5 marcados como "crÃ­ticos"
- **Sin contexto 5G**: No consideraba infraestructura afectada

### SoluciÃ³n: Smart Labeling

Sistema de scoring multifactorial que considera:

âœ… **Pesos por tipo** - RCE (1.0) > DoS (0.45)  
âœ… **Infraestructura 5G** - AMF/SMF crÃ­ticos (+60%)  
âœ… **Keywords peligrosas** - "unauthenticated", "pre-auth" (+40%)  
âœ… **Edad del CVE** - MÃ¡s recientes = mÃ¡s peligrosos  
âœ… **Thresholds dinÃ¡micos** - DoS necesita >0.70, RCE >0.50  

---

## ðŸ”§ InstalaciÃ³n

### Dependencias

AÃ±ade a `requirements.txt`:

```txt
python-dateutil>=2.8.2
```

Instala:

```bash
pip install -r requirements.txt
```

### Archivos Nuevos

Copia estos archivos a `services/ia/`:

1. `smart_labeling.py` - Sistema de scoring
2. `label_validator.py` - ComparaciÃ³n de mÃ©todos
3. `retrain_with_smart_labels.py` - Re-entrenamiento
4. `run_predict.py` - Endpoint de predicciÃ³n

---

## ðŸ—ï¸ Arquitectura

```
services/ia/
â”œâ”€â”€ smart_labeling.py          # ðŸ§  Cerebro del sistema
â”‚   â”œâ”€â”€ calculate_exploit_score()  # Score 0-1
â”‚   â”œâ”€â”€ smart_label()              # Etiquetado individual
â”‚   â”œâ”€â”€ smart_label_batch()        # Procesamiento masivo
â”‚   â””â”€â”€ explain_label()            # Explicaciones
â”‚
â”œâ”€â”€ label_validator.py         # ðŸ“Š AnÃ¡lisis comparativo
â”‚   â”œâ”€â”€ compare_methods()          # Old vs New
â”‚   â”œâ”€â”€ analyze_comparison()       # EstadÃ­sticas
â”‚   â””â”€â”€ generate_report()          # Reportes CSV
â”‚
â”œâ”€â”€ retrain_with_smart_labels.py  # ðŸš€ Re-entrenamiento
â”‚   â””â”€â”€ Entrena modelo V2 con smart labels
â”‚
â”œâ”€â”€ run_predict.py            # ðŸŽ¯ Predicciones
â”‚   â”œâ”€â”€ predict_single_cve()      # Un CVE
â”‚   â”œâ”€â”€ predict_top_risks()       # Top N
â”‚   â””â”€â”€ predict_batch()           # Todos
â”‚
â””â”€â”€ train_exploit_model.py    # ðŸ”„ Actualizado
    â””â”€â”€ Soporta --smart-labels flag
```

---

## âš¡ Uso RÃ¡pido

### 1. Comparar MÃ©todos de Etiquetado

```bash
python services/ia/label_validator.py
```

**Output:**
```
ðŸ“ˆ ETIQUETAS POSITIVAS (explotables):
   MÃ©todo original: 192 (58.0%)
   Smart labeling:  145 (43.8%)
   Diferencia: -47 (-14.2%)

ðŸ” ANÃLISIS ESPECÃFICO: DenegaciÃ³n de Servicio
   ReducciÃ³n: 42 CVEs (43.8%)
```

### 2. Re-entrenar con Smart Labels

```bash
python services/ia/retrain_with_smart_labels.py
```

**Output:**
```
ðŸ·ï¸ SMART LABELING - RESUMEN
âœ… Explotables: 145 (43.8%)
âŒ No explotables: 186 (56.2%)

ðŸ“Š RESULTADOS V2 (Test Set):
              precision    recall  f1-score
Explotable       0.89      0.92      0.91
```

### 3. Calibrar Modelo V2

```bash
python services/ia/calibrate_exploit_model.py --version v2
```

### 4. Hacer Predicciones

```bash
# Un CVE especÃ­fico con explicaciÃ³n
python services/ia/run_predict.py --cve CVE-2023-41627 --explain

# Top 20 mÃ¡s peligrosos
python services/ia/run_predict.py --top 20 --min-cvss 7.0

# Batch completo
python services/ia/run_predict.py --batch --output predictions.json
```

---

## ðŸ“š Scripts Disponibles

### `smart_labeling.py`

**FunciÃ³n principal:** `calculate_exploit_score(cve) -> (score, metadata)`

**Ejemplo:**
```python
from smart_labeling import calculate_exploit_score, smart_label

# Scoring detallado
score, metadata = calculate_exploit_score(cve)
print(f"Score: {score:.3f}")
print(f"Tipo weight: {metadata['tipo_weight']}")
print(f"Adjustments: {metadata['final_adjustments']}")

# Etiquetado simple
label = smart_label(cve)  # 0 o 1
```

**Pesos configurables:**

Edita `TIPO_WEIGHTS` y `INFRA_MULTIPLIERS` en el archivo para ajustar:

```python
TIPO_WEIGHTS = {
    "EjecuciÃ³n remota": 1.0,      # MÃ¡ximo
    "DenegaciÃ³n de servicio": 0.45,  # Reducido
    "Sin clasificar": 0.15,        # Penalizado
}

TIPO_THRESHOLDS = {
    "EjecuciÃ³n remota": 0.50,      # MÃ¡s permisivo
    "DenegaciÃ³n de servicio": 0.70,  # MÃ¡s restrictivo
}
```

---

### `label_validator.py`

**Uso:**
```bash
# AnÃ¡lisis completo
python label_validator.py

# Modo interactivo
python label_validator.py --interactive
```

**Reportes generados:**

```
reports/
â”œâ”€â”€ label_comparison_full.csv     # Todos los CVEs
â”œâ”€â”€ label_discrepancias.csv       # Solo diferencias
â”œâ”€â”€ label_summary_by_type.csv     # Resumen por tipo
â””â”€â”€ cases_for_review.csv          # Alta severidad
```

---

### `retrain_with_smart_labels.py`

**Proceso:**

1. Carga CVEs desde MongoDB
2. Genera labels con Smart Labeling
3. Entrena modelo V2
4. Compara con V1 (si existe)
5. Guarda modelo V2

**Archivos generados:**

```
models/
â”œâ”€â”€ exploit_model_v2.joblib       # Modelo re-entrenado
â””â”€â”€ featurizer_v2.joblib          # Featurizer actualizado
```

---

### `run_predict.py`

**Modos de uso:**

```bash
# 1. PredicciÃ³n individual
python run_predict.py --cve CVE-2024-1234

# 2. Con explicaciÃ³n detallada
python run_predict.py --cve CVE-2024-1234 --explain

# 3. Top N mÃ¡s peligrosos
python run_predict.py --top 20 --min-cvss 7.0 --output top20.json

# 4. Procesamiento batch
python run_predict.py --batch --output all_predictions.json

# 5. Especificar versiÃ³n del modelo
python run_predict.py --cve CVE-2024-1234 --model v2
```

**Output ejemplo:**

```json
{
  "cve_id": "CVE-2023-41627",
  "exploit_probability": 0.9992,
  "risk_level": "CRITICAL",
  "cvss_score": 7.5,
  "tipo": "EjecuciÃ³n remota",
  "componente": "Open5GS"
}
```

---

## ðŸ”„ Workflow Completo

### Escenario 1: Primera Vez

```bash
# 1. Ingestar datos con telemetrÃ­a
python ingest_main.py

# 2. Entrenar modelo con smart labels
python services/ia/retrain_with_smart_labels.py

# 3. Calibrar modelo
python services/ia/calibrate_exploit_model.py --version v2

# 4. Hacer predicciones
python services/ia/run_predict.py --top 10
```

### Escenario 2: Mejorar Modelo Existente

```bash
# 1. Comparar mÃ©todos de etiquetado
python services/ia/label_validator.py

# 2. Revisar reportes
cat reports/label_summary_by_type.csv

# 3. Ajustar thresholds en smart_labeling.py si necesario

# 4. Re-entrenar
python services/ia/retrain_with_smart_labels.py

# 5. Comparar V1 vs V2
# (automÃ¡tico en el script anterior)
```

### Escenario 3: AnÃ¡lisis de Vulnerabilidades Nuevas

```bash
# 1. Ingestar nuevos CVEs
python ingest_main.py

# 2. Predecir riesgos
python services/ia/run_predict.py --batch --output latest.json

# 3. Filtrar crÃ­ticos
jq '.[] | select(.risk_level == "CRITICAL")' latest.json
```

---

## ðŸ“Š InterpretaciÃ³n de Resultados

### Quality Score (AuditorÃ­a)

Generado por telemetrÃ­a en ingesta:

- **80-100**: Excelente - Datos completos
- **60-80**: Bueno - Algunos campos vacÃ­os
- **40-60**: Regular - Revisar manualmente
- **0-40**: Malo - Re-procesar CVE

### Exploit Probability

Score del modelo calibrado (0.0-1.0):

- **â‰¥0.75**: ðŸ”´ CRITICAL - AcciÃ³n inmediata
- **0.50-0.75**: ðŸŸ  HIGH - Priorizar
- **0.25-0.50**: ðŸŸ¡ MEDIUM - Monitorear
- **<0.25**: ðŸŸ¢ LOW - Bajo riesgo

### Smart Label Score

Score interno de smart labeling (0.0-1.0):

Componentes:
```
final_score = (
    base_cvss * 
    tipo_weight * 
    cvss_multiplier * 
    infra_multiplier * 
    age_factor
) + keyword_bonus + exploit_bonus
```

---

## ðŸ” FAQ

### Â¿CuÃ¡ndo usar mÃ©todo original vs smart labeling?

**Original:**
- Datasets pequeÃ±os (<100 CVEs)
- Sin informaciÃ³n de infraestructura 5G
- Para comparaciÃ³n con versiones anteriores

**Smart Labeling:**
- Datasets grandes (>300 CVEs)
- Contexto 5G disponible
- Necesidad de reducir falsos positivos

---

### Â¿CÃ³mo ajustar thresholds?

Edita `smart_labeling.py`:

```python
TIPO_THRESHOLDS = {
    "EjecuciÃ³n remota": 0.50,  # Bajar para mÃ¡s sensibilidad
    "DenegaciÃ³n de servicio": 0.70,  # Subir para mÃ¡s especificidad
}
```

**Efecto:**
- Threshold mÃ¡s **bajo** â†’ MÃ¡s CVEs clasificados como explotables
- Threshold mÃ¡s **alto** â†’ Menos CVEs clasificados como explotables

---

### Â¿QuÃ© hacer si V2 no supera a V1?

1. **Revisar distribuciÃ³n de labels:**
   ```bash
   python label_validator.py
   ```

2. **Ajustar pesos:**
   - Incrementar `TIPO_WEIGHTS` para tipos crÃ­ticos
   - Reducir thresholds para tipos importantes

3. **Verificar datos:**
   ```bash
   python ingest_main.py --debug
   ```

4. **Re-entrenar con mÃ¡s datos:**
   - Ingestar mÃ¡s CVEs desde NVD
   - Verificar calidad con telemetrÃ­a

---

### Â¿CÃ³mo explicar predicciones a no tÃ©cnicos?

Usa `--explain` flag:

```bash
python run_predict.py --cve CVE-2024-1234 --explain
```

Output incluye:
- Score final y threshold usado
- Componentes del cÃ¡lculo
- Condiciones CVSS detectadas
- Ajustes aplicados con razones

---

### Â¿Puedo usar smart labeling fuera de este proyecto?

SÃ­, `smart_labeling.py` es independiente:

```python
from smart_labeling import calculate_exploit_score

cve = {
    "cve_id": "CVE-2024-1234",
    "cvssv3": {"score": 8.5, "vector": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H"},
    "tipo": "EjecuciÃ³n remota",
    "descripcion_general": "Remote code execution via unauthenticated API",
    "infraestructura_5g_afectada": ["AMF"],
    "referencias_mitre": ["https://exploit-db.com/exploits/12345"]
}

score, metadata = calculate_exploit_score(cve)
print(f"Exploit score: {score:.3f}")
```

---

## ðŸ“ž Soporte

Para problemas o mejoras:

1. Revisa logs de telemetrÃ­a: `reports/ingest_metrics.json`
2. Compara labels: `python label_validator.py`
3. Verifica modelos: `ls -lh models/`


**VersiÃ³n:** 2.0  
**Ãšltima actualizaciÃ³n:** Diciembre 2024